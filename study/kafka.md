## 카프카 
[카프카 핵심 가이드](http://www.yes24.com/Product/Goods/65418488) 및 웹 정보 참조해서 작성하였습니다.

### 20210817
### 1장 카프카 훑어보기

- 기원 : 링크드인 내부 인프라 시스템에서 시작 : 지속적인 데이터 흐름 처리
- 끊임없이 진화하고 성장하는 스트림으로 데이터 처리하는 데 중점 둔 시스템
- 스트리밍 플랫폼 : 데이터 스트림을 쓰고 읽고 저장하고 처리하는 시스템
- 메시지 스트림을 쓰고 읽게 해주는 메시징 시스템
- 실시간 이벤트 스트림 처리 지향

특징
- 클러스터로 실행, 큰 규모 앱 처리 가능한 확장 가능한 분산 시스템
    - 클러스터란 ?
    - 앱 수동 연결하는 개별적 메시징 브로커 대신 카프카는 회사의 모든 데이터 스트림 처리 위해 탄력적 확장 가능한 중심 플랫폼 역할
- 충분한 기간 동안 데이터 저장
    - 신뢰성 있는 데이터 전달 확실히 보장 -> 서로 다른 시스템의 연결 계층으로 사용 가능
    - 카프카 데이터는 복제되고 영구적이며 원하는 만큼 보존 가능
- 더 적은 코드 사용해서 우리 스트림으로부터 파생된 다른 스트림과 데이터세트 산출할 수 있는 스트림 프로세싱 능력


- 스트림 프로세싱은 지속적이며 지연 적은 데이터 전달 및 처리 가능, 배치 프로세싱의 상위 개념
    - 배치 프로세싱?

- 장점
    - 메시지 분실 위험성 감소
    - 데이터 스트림 처리 위한 
    - 소스 앱과 타켓 앱의 커플링 약하게 하기 위해 나옴
      - 데이터 전송 라인이 많아지면 배포와 장애에 대응하기 어려워짐
      - 데이터를 전송할 때 프로토콜 포맷의 파편화가 심각해짐
        - 추후 데이터 포맷 내부 변경사항 있을 때 유지 보수 매우 어려워짐
    - 고가용성
      - 고가용성(高可用性, HA, High Availability)이란 서버와 네트워크, 프로그램 등의 정보 시스템이 상당히 오랜 기간 동안 지속적으로 정상 운영이 가능한 성질을 말한다. 고(高)가용성이란 "가용성이 높다"는           뜻으로서, "절대 고장 나지 않음"을 의미
      - 서버 이슈 또는 랙이 내려 가는 경우에도 데이터 손실 없이 복구 가능
    - 낮은 지연(latency)과 높은 처리량(throughput)

#### 메시지 발행/구독
- 데이터의 기본 단위
  - 데이터베이스의 행이나 레코드
  - 바이트 배열의 데이터
- 발행자가 구독자에게 직접 전송 X
- 어떤 형태로 구분해서 발행/구독 시스템에 전송하면 구독자가 특정 부류의 메시지 구독
- 브로커 : 발행된 메시지 저장, 중계
- 토픽으로 분류해서 파티션에 수록
  - 토픽은 쉽게 말해 큐
  - 데이터 수록할 파티션 결정 위해  일관된 해시 값으로 키 생성
  - 여러 개 메시지 모아서 배치(BATCH) 형태로 파티션에 수록
    - 대기 시간(LATenCY) < - > 처리량(THROUGHPUT)
    - 배치에 데이터 압축 적용

#### 스키마
- 메시지 내용 이해하기 쉽도록 구조를 나타내는 것
- 여러 표준 형식 : JSON, XML 등
- Avro : 직렬화 프레임워크
    - 스키마를 유지 관리 -> 스키마 변경돼도 앱의 코드 추가 변경 필요 없음
    - 강력한 데이터 타입 지원, 버전간 호환성 좋음
- 카프카에선 일관된 데이터 형식 중요
    - 메시지 쓰기와 읽기 분리해서 할 수 있기 때문
- 잘 정의된 스키마를 공유 리포지터리에 저장해 사용할 수 있으므로 앱 변경 없이 메시지 처리 가능

#### 토픽과 파티션
- 데이터베이스 테이블, 파일 시스템의 폴더와 유사
- 하나의 토픽은 여러 개의 파티션
- 메시지는 파티션에 추가되는 형태로만 수록, 맨 앞부터 끝까지의 순서로 읽힌다.
- 메시지 처리 순서는 파티션별로 유지 관리
- 메시지는 파티션의 끝에 수록
- 각 파티션은 서로 다른 서버에 분산 가능 -> 단일 서버보다 우수한 성능
- ‘스트림’ 은 하나의 토픽 데이터
    - 프로듀서로부터 컨슈머로 이동되는 연속적인 데이터
    - 실시간으로 메시지 처리할 때 사용되는 방법

#### 프로듀서 & 컨슈머
- 큐(토픽)에 데이터 넣는 역할은 프로듀서가, 가져가는 역할은 컨슈머가
- 프로듀서와 컨슈머는 라이브러리로 돼 있어서 앱에서 구현 가능.
- 메시지는 특정 토픽으로 생성
    - 프로듀서는 메시지가 어떤 파티션에 수록되는 지 관여 안함
        - 특정 파티션에 쓰는 것도 가능 
            - 이 때는 메시지 키와 파티셔너 사용
                - 파티셔너 : 키의 해시 값을 생성하고 이를 특정 파티션에 대응시켜 지정된 키를 갖는 메시지를 항상 같은 파티션에 수록
- 컨슈머는 하나 이상의 토픽 구동해 메시지가 생성된 순서로 읽음
    - 메시지 오프셋을 유지해 읽는 메시지의 위치 알 수 있음.
        - 오프셋 : 지속적으로 증가하는 정숫값, 메시지 생성 시 카프카가 추가해 줌.
    - 주키퍼나 카프카에서 마지막 읽은 메시지 오프셋 저장
- 컨슈머는 컨슈머 그룹의 멤버
    - 한 토픽을 소비(읽고 처리)하기 위해 같은 그룹의 여러 컨슈머 함께 동작
    - 한 토픽의 각 파티션은 하나의 컨슈머만 소비 가능 : 파티션 소유권(ownership)

#### 브로커와 클러스터
- 브로커 : 하나의 카프카 서버
    - 프로듀서로부터 메시지 수신하고 오프셋 지정한 뒤 디스크에 저장
    - 컨슈머의 파티션 읽기 요청에 응답하고 디스크에 수록된 메시지 전송
    - 하나의 브로커는 초당 수천 개의 토픽과 수백만 개의 메시지 처리 가능
    - 클러스터의 일부로 동작
        - 클러스터의 여러 브로커 중 하나가 클러스터 컨트롤러로 자동으로 선정
        - 컨트롤러는 클러스터의 각 브로커에게 담당 파티션 할당하고 모니터링
        - 각 파티션은 클러스터의 한 브로커가 소유, 그 브로커는 파티션 리더
            - 각 파티션 사용하는 모든 컨슈머와 프로듀서는 파티션 리더에 연결해야 함
        - 같은 파티션이 여러 브로커에 지정되면 해당 파티션이 복제
            - 해당 파티션의 메시지 중복 저장
            - 관련 브로커에 장애 생기면 다른 브로커가 소유권 받아 그 파티션 처리
    - 메시지 보존(Retention)
        - 토픽이 일정 기간 또는 일정 크기 될 때까지 보존
            - 한도 도달 시 만료 메시지 삭제
            - 토픽마다 보존 설정 다르게 가능

#### 다중 클러스터????
- 장점
    - 데이터 타입에 따라 구분해서 처리
    - 보안 요구사항 분리해서 처리
    - 재해 복구 대비한 다중 데이터센터 유지
- 메시지가 데이터센터 간 복제돼야 함
    - 카프카 클러스터 복제 메커니즘은 단일 클러스터에서만 동작
        - 미러메이커가 다중클러스터 지원( in 카프카 프로젝트)
            - 미러메이커도 카프카의 컨슈머와 프로듀서, 각 미러메이커는 큐로 상호 연결
            - 하나의 카프카 클러스터에서 소비된 메시지를 다른 클러스터에서도 사용할 수 있도록 생성

#### 카프카 사용하는 이유
- 다중 프로듀서
- 다중 컨슈머
    - 많은 컨슈머가 상호 간섭 없이 어떤 메시지 스트림도 읽을 수 있게 지원
    - 컨슈머는 컨슈머 그룹의 멤버가 되어 메시지 스트림 공유
- 디스크 기반의 보존
    - 보존 옵션에 따라 토픽별로 메시지 보존
        - 프로듀서는 메시지 백업 필요X
        - 컨슈머가 다시 실행되면 중단 시점부터 메시지 처리
- 확장성
    - 확장 작업이 시스템 전체의 사용에 영향 주지 않음
    - 클러스터가 온라인 상태일 때도 수행 가능
- 고성능
    - 대용량 메시지 스트림 쉽게 처리할 수 있도록 확장, 확장 작업 1초 미만
    
    
    
### 2장 설치 및 구성
설치 생략([SpringBootKafkaConnection](https://oss.navercorp.com/order-internship/2021-internship-first/blob/master/study/SpringBootKafkaConnection.md#%ED%99%98%EA%B2%BD-%EC%84%B8%ED%8C%85) 참조)

#### 브로커 구성

- 핵심 구성 옵션
  - 어떤 환경으로 카프카 설치하든 반드시 검토해야 하는 브로커 매개변수들
    - 대부분 변경 요망
  - broker.id
    - 기본값 0, 하나의 클러스터 내에서 고유한 값 : 본질적인 값 권장
    - 임의 선택 가능, 브로커 간 변경 가능
  - port
    - 카프카 실행에 사용되는 TCP 포트 : 기본값 9092
    - 1024 미만 값은 root 권한 필요 : 비권장
  - zookeepr.connect
    - 주키퍼 위치 : 기본값 localhost:2181
    - 호스트이름:포트/경로
      - /경로 : 카프카 클러스터의 chroot(리눅스 가상 root 경로 설정 명령) 환경에서 사용될 주키퍼의 chroot 경로, 기본값 실제 root 경로
        - chroot 경로 사용을 권장
  - log.dirs
    - 카프카는 모든 메시지를 로그 세그먼트 파일에 모아서 디스크에 저장 -> log.dirs 지정 디렉토리에 저장
    - 경로 여러 개(쉼표 구분) 모든 경로에 파티션 저장
    - 새로운 파티션 저장할 때는 가장 적은 파티션을 저장한 경로에 저장
  - num.recovery.threads.per.data.dir
    - 스레드 풀(thread pool) 이용해 로그 세그먼트 처리
      - 스레드 풀 : 스레드 개수 제한해 생성 후 번갈아 사용
  - auto.create.topics.enable
    - 프로듀서가 토픽에 메시지 쓸 때
    - 컨슈머가 토픽의 메시지 읽기 시작할 때
    - 클라이언트에서 토픽의 메타데이터 요청할 때
    
#### 토픽의 기본 설정
- 파티션 개수, 메시지 보존 설정 등 : 관리 도구(9장) 사용해 토픽마다 설정
- num.partitions
  - 새로운 토픽이 몇 개의 파티션으로 생성되는 지, 기본값 1
  - 파티션 개수 산정 방법 : p28
- log.retention.ms
  - 얼마 동안 메시지 보존할 지, 기본값 1주일
  - mtime(로그 세그먼트 파일의 마지막 수정 시간) 기준
- log.retention.bytes
  - 파티션 기준
  - log.retnetion.ms와 동시 적용 시 둘 중 하나라도 만족하면 삭제
- log.segment.bytes
  - 로그 세그먼트 파일 닫히는 제한
- log.segment.ms
- message.max.bytes
  - 브로커가 쓰려는 메시지 최대 크기
  
  
#### 20210818
#### 하드웨어 선택
- 디스크 처리량, 용량, 메모리, 네트워크, CPU 고려
  - 디스크 처리량
    - 로그 세그먼트 저장 시
    - 카프카 메시지는 생성될 때 서버의 로컬 스토리지에 커밋, 최소 한 브로커가 확인해줄 때까지 프로듀서 클라이언트는 기다림
  - 디스크 용량
  - 메모리
    - 컨슈머가 읽는 파티션의 메시지는 시스템 메모리의 페이지 캐시에 최적화되어 저장
    - 카프카는 JVM에서 실행
  - 네트워크 처리량
    - 카프카가 처리할 수 있는 통신 트래픽의 최대량
    - 디스크 스토리지와 더불어 클러스터 크기 조정의 주된 요소
  - CPU
    - 주된 요소 아님
#### 클라우드에서 카프카 사용
- 클라우드 인스턴스 선택 시 카프카의 다양한 성능 특성 고려 : 다음 순서
  1. 데이터 보존량
  2. 프로듀서가 필요로 하는 성능
#### 카프카 클러스터
- 다수의 브로커 서버를 하나의 클러스터로 구성 시 장점 많음
  - 다수의 서버로 처리량 분산 확장시켜 확장 가능
  - 데이터 유실 막기 위해 복제 가능
  - 복제 시 시스템 중단 없이 유지보수 가능
- 브로커 개수
  1. 메시지 보존하는 데 필요한 디스크 용량, 하나의 브로커에 사용 가능한 스토리지 크기
    - 클러스터에서 10TB 보존해야 되고 하나의 브로커가 2TB까지 사용 가능하면 최소 5개의 브로커 필요, 복제 시 두 배
  2. 요청을 처리하기 위한 클러스터의 용량
    - 네트워크 인터페이스의 처리 능력이 어떤 지
    - 클라이언트 트래픽이 일정하지 않더라도 모든 클라이언트의 트래픽을 처리할 수 있는 지
    > 무슨 뜻이지??
    > 한 브로커의 네트워크 인터페이스가 피크 시 80%의 컨슈머 트래픽 처리에 사용되고 해당 데이터를 사용하는 ㅓㄴ슈머가 둘이라면, 피크 시의 컨슈머 트래픽을 처리하기 위해 두 개의 브로커가 있어야       한다.
    
- 브로커 구성
  - 하나의 클러스터에 다수의 브로ㅓ 사용할 떄는 두 가지만 고려
    1. 모든 브로커의 구성 파일에 있는 zookeeper.connect 매개변수 값 동일하게
      - 주키퍼 앙상블과 경로 지정
    2. broker.id 매개변수에는 클러스터의 모든 브로커가 고유한 값 갖도록 지정
#### 운영체제 조정하기
- 카프카 브로커 성능 향상을 위해 몇 가지 변경 필요 : 가상 메모리, 네트워크 서브시스템, 디스크 마운트
  - 대개 /etc/sysctl.conf 파일에 저장
  - 자세한 내용은 리눅스 배포판 문서 참고
  - 가상 메모리
    - 스와핑 막아야 함
      > 스와핑?? : 메모리에서 뒤로 빠졌다가 다시 돌아오는 것([참조](https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&blogId=manhwamani&logNo=220736785025))
  - 네트워크
    - 대용량 초고속 데이터 전송에 맞게 조정
#### 실제 업무 시 고려사항
- 주키퍼 공동 사용하기
  - 주키퍼로 브로커, 토픽, 파티션에 관한 메타데이터 정보 저장
    - 컨슈머 그룹 멤버십 변경사항이나 카프카 클러스터 변경사항 생길 때만 주키퍼에 쓰기, 트래픽 아주 적음
  - 단일 카프카 클러스터에 주키퍼 앙상블 사용 권장 안함
  - 대부분 다수의 클러스터에 하나의 주키퍼 앙상블
  - 오프셋 커밋은 주키퍼 트래픽 많이 발생시킬 수 있음
  - 서로 다른 애플리케이션은 다른 주키퍼 앙상블 궈장
    
### 3장 메시지 쓰기
4장부터 파악
포스트맨에서 POST로 키, 값 전달 시 스프링에서 메시지 발행 확인.
- 아파치 카프카는 클라이언트 API 포함해서 배포
- 프로듀서 작성 및 사용법
  1. 프로듀서의 개념, 관련 컴포넌트
    - 이번 과제에서 카프카 요구사항 분석
      - 메시지가 하나도 유실되면 안됨.
      - 메시지 복제돼선 안됨?
      - 처리 대기 시간 일정 시간 미만
      - 초당 백만 개의 메시지?
    - 실행 순서
      1. 제일 먼저 ProducerRecord 생성
        - 토픽과 값은 지정
        - 선택적으로 키와 파티션 지정
      2. 메시지 객체들이 네트워크로 전송될 수 있도록 바이트 배열로 직렬화 : 직렬처리기 컴포넌트(클래스)가 처리
      3. 해당 데이터 파티셔너 컴포넌트에 전달
        - 파티션 지정 안하면 ProducerRecord의 키 기준으로 파티셔너가 하나의 파티션 선택
        - 같은 토픽과 파티션으로 전송될 레코드(ProducerRecord 객체)들을 레코드 배치에 추가, 별개의 스레드가 배치를 카프카 브로커에게 전송
      4. 브로커는 레코드의 메시지 처리 후 응답 전송
        - 성공 시 RecordMetadata 객체 반환 : 토픽, 파티션, 파티션 내부 메시지 오프셋
        - 실패시 에러 반환 : 재전송 또는 포기
      
  2. KafkaProducer와 ProducerRecord 객체 생성 방법
    - 제일 먼저 프로듀서 기능 수행하는 객체 생성
      - 다음 세 개의 필수 속성 : 반드시 프로듀서 객체에 설정
        1. bootstrap.servers : 카프카 클러스터에 최초로 연결하기 위해 브로커들의 host:port 목록을 이 속성에 설정
          - 두 개 이상 host:port 궈장
        2. key.serializer : 레코드의 메시지 키 직렬화하기 위해 사용되는 클래스 이름
          - 카프카 브로커는 바이트 배열로 키와 값의 쌍으로 된 메시지를 받는다
        3. value.serializer : 레코드의 메시지 값을 직렬화하는 데 사용되는 클래스 이름
      
  3. 카프카에 데이터 전송하는 방법
  4. 에러 처리법
  5. 프로듀서 실행 제어 중요 구성 옵션
  6. 파티션 처리 방법, 직렬처리기 사용 작성 방법
  
### 4장 카프카에서 데이터 읽기
터미널 또는 포스트맨 POST로 키, 값 전달 시 메시지 소비 확인




#### 20210831
[참조](https://www.popit.kr/kafka-%EC%9A%B4%EC%98%81%EC%9E%90%EA%B0%80-%EB%A7%90%ED%95%98%EB%8A%94-%EC%B2%98%EC%9D%8C-%EC%A0%91%ED%95%98%EB%8A%94-kafka/)
- 주키퍼는 과반수 투표방식으로 결정하기 때문에 홀수로 구성해야 하고, 과반수 이상 살아 있으면 정상으로 동작
- 카프카는 과반수 투표방식을 사용하지 않지만, Replication Factor를 3으로 할 경우 균일하게 스프레드하기 위해서 노드 수 3이 최소라고 생각합니다. (__consumer_offsets 토픽은 기본값이 RF3)
  
